{"cells": [{"cell_type": "markdown", "id": "6d7f5a2c", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<hr style=\"height: 1px;\">\n", "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n", "<hr style=\"height: 1px;\">\n", "<br>\n", "\n", "<h1>Lesson 14: An Example With LHC Data</h1>\n"]}, {"cell_type": "markdown", "id": "ff95d3bc", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_14_0'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L14.0 Overview</h2>\n"]}, {"cell_type": "markdown", "id": "91dd7386", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<h3>Navigation</h3>\n", "\n", "<table style=\"width:100%\">\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_14_1\">L14.1 Large Hadron Collider Data</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_14_1\">L14.1 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_14_2\">L14.2 Loading Data and Defining the Network</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_14_2\">L14.2 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_14_3\">L14.3 Training and Testing the Network</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_14_3\">L14.3 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_14_4\">L14.4 Adding a Hidden Layer</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_14_4\">L14.4 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_14_5\">L14.5 Regularization, Batch Normalization, and Dropout</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_14_5\">L14.5 Exercises</a></td>\n", "    </tr>\n", "</table>\n", "\n"]}, {"cell_type": "markdown", "id": "d0a32547", "metadata": {"tags": ["learner", "catsoop_00", "md"]}, "source": ["<h3>Learning Objectives</h3>\n", "\n", "This lesson covers topics related to analysis of data from experiments at the Large Hadron Collider (LHC), including how to work with LHC data, how to train and test a network, and how to add a hidden layer to the network.\n", "\n", "The topics include the following:\n", "\n", "- Large Hadron Collider Data\n", "- Working with LHC Data\n", "- Training and Testing the Network\n", "- Adding a Hidden Layer"]}, {"cell_type": "markdown", "id": "624022da", "metadata": {"tags": ["learner", "md", "catsoop_00", "learner_chopped"]}, "source": ["<h3>Data</h3>\n", "\n", ">description: CMS Crystal Shower Shape Data<br>\n", ">source: https://zenodo.org/record/8035308 <br>\n", ">attribution: Rankin, Dylan (CMS Collaboration), DOI:10.5281/zenodo.8035308 "]}, {"cell_type": "code", "execution_count": null, "id": "9dab2f77", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.0-runcell00\n", "\n", "# NOTE: these files are too large to include in the original repository, so you must download them from here:\n", "# https://www.dropbox.com/s/i1dbakzr3pn9twd/xtalTuple_TTbar_PU0.z?dl=0\n", "#\n", "# Ways to download:\n", "#     1. Copy/paste the link (replace =0 with =1 to download automatically)\n", "#     2. Use the wget commands below (works in Colab, but you may need to install wget if using locally)\n", "#\n", "# Location of files:\n", "#     Move the files to the directory data/L14\n", "#\n", "# Using wget: (works in Colab)\n", "#     Upon downloading, the code below will move them to the appropriate directory\n", "\n", "#get the data\n", "!wget -P data/L14 https://www.dropbox.com/s/i1dbakzr3pn9twd/xtalTuple_TTbar_PU0.z?dl=0\n", "!mv data/L14/xtalTuple_TTbar_PU0.z?dl=0 data/L14/xtalTuple_TTbar_PU0.z "]}, {"cell_type": "markdown", "id": "a651180b", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Importing Libraries</h3>\n", "\n", "Before beginning, run the cell below to import the relevant libraries for this notebook.\n"]}, {"cell_type": "code", "execution_count": null, "id": "51c9b869", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.0-runcell01\n", "\n", "#If using notebooks locally, run the following within your conda environment (if not done already)\n", "#conda install pandas\n", "\n", "import numpy as np               #https://numpy.org/doc/stable/\n", "import matplotlib.pyplot as plt  #https://matplotlib.org/3.5.3/api/_as_gen/matplotlib.pyplot.html\n", "import h5py                      #https://docs.h5py.org/en/stable/quick.html#quick\n", "import pandas as pd              #https://pandas.pydata.org/docs/user_guide/index.html\n", "import torch                     #https://pytorch.org/docs/stable/torch.html"]}, {"cell_type": "markdown", "id": "7fb9f893", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Setting Default Figure Parameters</h3>\n", "\n", "The following code cell sets default values for figure parameters."]}, {"cell_type": "code", "execution_count": null, "id": "ba828ee6", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.0-runcell02\n", "\n", "#set plot resolution\n", "%config InlineBackend.figure_format = 'retina'\n", "\n", "#set default figure parameters\n", "plt.rcParams['figure.figsize'] = (9,6)\n", "\n", "medium_size = 12\n", "large_size = 15\n", "\n", "plt.rc('font', size=medium_size)          # default text sizes\n", "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n", "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n", "plt.rc('legend', fontsize=medium_size)    # legend\n", "plt.rc('axes', titlesize=large_size)      # axes title\n", "plt.rc('axes', labelsize=large_size)      # x and y labels\n", "plt.rc('figure', titlesize=large_size)    # figure title\n"]}, {"cell_type": "markdown", "id": "05535af7", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_14_1'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L14.1 Large Hadron Collider Data</h2>  \n", "\n", "| [Top](#section_14_0) | [Previous Section](#section_14_0) | [Exercises](#exercises_14_1) | [Next Section](#section_14_2) |\n"]}, {"cell_type": "markdown", "id": "d2c69377", "metadata": {"tags": ["learner", "md"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.2x+1T2025/block-v1:MITxT+8.S50.2x+1T2025+type@sequential+block@seq_LS14/block-v1:MITxT+8.S50.2x+1T2025+type@vertical+block@vert_LS14_vid1\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "id": "1ad92a2b", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Slides</h3>\n", "\n", "Run the code below to view the slides for this section, which are discussed in the related video. You can also open the slides in a separate window <a href=\"https://mitx-8s50.github.io/slides/L14/slides_L14_01.html\" target=\"_blank\">HERE</a>."]}, {"cell_type": "code", "execution_count": null, "id": "73dfe0cc", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.1-slides\n", "\n", "from IPython.display import IFrame\n", "IFrame(src='https://mitx-8s50.github.io/slides/L14/slides_L14_01.html', width=970, height=550)"]}, {"cell_type": "markdown", "id": "c7e547b8", "metadata": {"tags": ["learner", "md", "lect_01"]}, "source": ["<h3>Overview</h3>\n", "\n", "The electromagnetic calorimeter (ECAL) is a key component of the CMS detector at the LHC. It is designed to measure the energy of photons and electrons produced in particle collisions. When a photon or electron enters the ECAL, it interacts with a lead tungstate crystal and produces a shower of secondary particles, which in turn deposit their energy in the crystal. This energy causes the crystal to scintillate, creating light which is collected by photodetectors and converted into an electrical signal. The intensity of the light is proportional to the total amount of energy deposited in the crystal. These crystals are long enough that both electrons and photons created in LHC collisions lose essentially all of their energy.\n", "\n", "As introduced in Lesson 9 and discussed in the video, pileup is an effect where other proton-proton collisions occur almost simultaneously with a primary collision, producing additional signals in the detector. This complicates the analysis of the data since the signals from the additional interactions can interfere with the measurement of the particles produced in the primary collision. This is one form of background in the ECAL data. The exercises for this Section will introduce another background process, namely how a neural network could separate photons from other particles that can mimic photons.\n", "\n", "In the next Section, we will continue to investigate how to analyze data and extract useful information in the presence of background."]}, {"cell_type": "markdown", "id": "71d5e72a", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_14_1'></a>     \n", "\n", "| [Top](#section_14_0) | [Restart Section](#section_14_1) | [Next Section](#section_14_2) |\n"]}, {"cell_type": "markdown", "id": "2c6d1ed0", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-14.1.1</span>\n", "\n", "The CMS ECAL is intended to identify photons and electrons. However, it is often the case that you can get particles that mimic photons and electrons. In particular, pions can leave large energy deposits in the ECAL. Charged pions will produce a charged track and shower in the calorimeter. These are usually not a problem since they can be identified by the fact that they also deposit energy in the Hadron Calorimeter behind the ECAL.\n", "\n", "On the other hand, neutral pions will decay into two photons that are close to each other (colinear). In fact, they are typically so close together that they look like a single photon. The problem that we would like to solve is the separation of neutral pion decays from photons directly from the original collision. Let's say we are looking for a process that decays to photons, for example the Higgs decay to two well-separated photons. Selecting the Higgs involves selecting two photons on top of backgrounds from *fake* photons. What could a neural network do to remove fake photons? \n", "\n", "A) Reduce the background by eliminating fake events that are produced from pions. This is done by selecting events that have a large probability of containing TWO real photons.\\\n", "B) Do nothing to the background, just help to make suggestions as to what is more likely background.\\\n", "C) Generate a weight for each event quantifying the likelihood that it contains real photons. This weight can be used to look for the Higgs.\\\n", "D) Reduce the background by eliminating fake events that are produced from pions. This is done by selecting events that have a large probability of containing ONE real photon.\n", "\n"]}, {"cell_type": "markdown", "id": "0336942a", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-14.1.2</span>\n", "\n", "If our dominant background comes from pions that decay into two nearby photons, what would allow us to discriminate these cases from real photons? Select all that apply:\n", "\n", "A) Calorimeter shapes that look like two energy blobs in the cells.\\\n", "B) Wider calorimeter shapes.\\\n", "C) A single high energy deposit.\\\n", "D) Calorimeter shapes that are wider in a specific direction.\n", "\n"]}, {"cell_type": "markdown", "id": "26607e2f", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_14_2'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L14.2 Loading Data and Defining the Network</h2>  \n", "\n", "| [Top](#section_14_0) | [Previous Section](#section_14_1) | [Exercises](#exercises_14_2) | [Next Section](#section_14_3) |\n"]}, {"cell_type": "markdown", "id": "e70f6526", "metadata": {"tags": ["learner", "md"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.2x+1T2025/block-v1:MITxT+8.S50.2x+1T2025+type@sequential+block@seq_LS14/block-v1:MITxT+8.S50.2x+1T2025+type@vertical+block@vert_LS14_vid2\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "id": "a0b910c7", "metadata": {"tags": ["learner", "md", "lect_02"]}, "source": ["<h3>Overview</h3>\n", "\n", "\n", "Now that we have trained a very simple network, let's go ahead and take a real physics dataset and train a neural network to analyze it. For this, we are going to train a neural network that does photon identification at the Large Hadron Collider.  In particular, we will construct a discriminator that outputs the probability that a particle that we reconstructed was a real or \"fake\" photon. A fake photon in this case is typically a pion. Pions consist of two quarks and the neutral ones can decay into a pair of photons that are so close that they effectively merge, thereby looking very similar to a single photon. Photon identification is an important problem and it is what we used to identify good photons that led to the Higgs boson discovery. We regularly update our photon identification to try to improve it, and it has used some sort of either deep learning or machine learning for the last 10 years at the LHC. Suffice it to say that this is an excellent machine learning problem. \n", "\n", "In this particular case, we will only use information from the ECAL and, therefore, will be trying to separate real egamma events (i.e. photons and electrons) from background (mostly pions). In order to do this separation, we will incorporate a large number of different variables for the reconstructed particles from the collision, most of which are based on the moments and energies of the distribution of signals from the electromagnetic calorimeter elements. \n", "\n", "In the full particle identification, data from other detectors is used to discriminate electrons from photons.\n", "\n", "In the last Lesson, we analyzed a very simple simulated dataset in which each event had only two variables (the location of the point in 2D space) and was identified as either blue or red. The goal was to find a procedure which would most accurately predict the color of an event given its location.\n", "\n", "Now, we will consider a much more complicated case. However, the new dataset again consists of a simulation with the critically important attribute of identifying which cases are real egamma events and which are not. The difference is that the events in this case have many more than just two variables.\n", "\n", "One last thing is that we will use `pandas` dataframes to process this. Pandas is one of the standard python data formats that is quite popular for machine learning. Let's go ahead and look at what we get!"]}, {"cell_type": "code", "execution_count": null, "id": "466f917d", "metadata": {"tags": ["learner", "py", "lect_02", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.2-runcell01\n", "\n", "import h5py\n", "import pandas as pd\n", "\n", "\n", "treename = 'l1pf_egm_reg'\n", "\n", "VARS = ['pt', 'eta', 'phi', 'energy',\n", "  'e2x2', 'e2x5', 'e3x5', 'e5x5', 'e2x2_div_e2x5', 'e2x2_div_e5x5', 'e2x5_div_e5x5',#7\n", "  'hoE', 'bremStrength', 'ecalIso', 'crystalCount',#4\n", "  'lowerSideLobePt','upperSideLobePt',#2\n", "  'phiStripContiguous0', 'phiStripOneHole0', 'phiStripContiguous3p', 'phiStripOneHole3p',#4\n", "  'sihih','sipip','sigetaeta','sigphiphi','sigetaphi',#5\n", "  'e_m2_m2','e_m2_m1','e_m2_p0','e_m2_p1','e_m2_p2',\n", "  'e_m1_m2','e_m1_m1','e_m1_p0','e_m1_p1','e_m1_p2',\n", "  'e_p0_m2','e_p0_m1','e_p0_p0','e_p0_p1','e_p0_p2',\n", "  'e_p1_m2','e_p1_m1','e_p1_p0','e_p1_p1','e_p1_p2',\n", "  'e_p2_m2','e_p2_m1','e_p2_p0','e_p2_p1','e_p2_p2',#^25\n", "  'h_m1_m1','h_m1_p0','h_m1_p1',\n", "  'h_p0_m1','h_p0_p0','h_p0_p1',\n", "  'h_p1_m1','h_p1_p0','h_p1_p1',#^9\n", "  'gen_match']\n", "\n", "filename = 'data/L14/xtalTuple_TTbar_PU0.z'\n", "\n", "h5file = h5py.File(filename, 'r') # open read-only\n", "params = h5file[treename][()]\n", "\n", "df = pd.DataFrame(params,columns=VARS)\n", "\n", "TODROP = [\n", "  'e2x2_div_e2x5', 'e2x2_div_e5x5', 'e2x5_div_e5x5',#7\n", "  'e_m2_m2','e_m2_m1','e_m2_p0','e_m2_p1','e_m2_p2',\n", "  'e_m1_m2','e_m1_m1','e_m1_p0','e_m1_p1','e_m1_p2',\n", "  'e_p0_m2','e_p0_m1','e_p0_p0','e_p0_p1','e_p0_p2',\n", "  'e_p1_m2','e_p1_m1','e_p1_p0','e_p1_p1','e_p1_p2',\n", "  'e_p2_m2','e_p2_m1','e_p2_p0','e_p2_p1','e_p2_p2',#^25\n", "  'h_m1_m1','h_m1_p0','h_m1_p1',\n", "  'h_p0_m1','h_p0_p0','h_p0_p1',\n", "  'h_p1_m1','h_p1_p0','h_p1_p1',#^9\n", "]\n", "\n", "df = df.drop(TODROP, axis=1) #remove custom variables\n", "\n", "#normalize the shower shapes by energy\n", "for ie in ['e2x2', 'e2x5', 'e3x5', 'e5x5']:\n", "    df[ie] /= df['energy']\n", "\n", "#add some labels\n", "df['isPU'] = pd.Series(df['gen_match']==0, index=df.index, dtype='i4')\n", "df['isEG'] = pd.Series(df['gen_match']==1, index=df.index, dtype='i4')\n", "\n", "#now select the dataset based on their transverse momentum (pt)\n", "MINPT = 0.5\n", "MAXPT = 100.\n", "df = df.loc[(df['pt']>MINPT) & (MAXPT>df['pt']) & (1.3>abs(df['eta']))]\n", "df.fillna(0., inplace=True)\n", "\n", "#take a fixed nubmer of events\n", "df0 = df[df['gen_match']==0].head(100000)\n", "df1 = df[df['gen_match']==1].head(10000)\n", "\n", "df = pd.concat([df0, df1], ignore_index=True)\n", "df = df.sample(frac=1).reset_index(drop=True)\n", "col_names = list(df.columns)\n", "\n", "#Now let's check it all\n", "print(df)\n", "print(sum(df['gen_match']==0))\n", "print(sum(df['gen_match']==1))"]}, {"cell_type": "markdown", "id": "00c71148", "metadata": {"tags": ["learner", "md", "lect_02"]}, "source": ["The problem at hand is that we are separating out egamma events (electrons or  photons) from background (mostly pions). The label `gen_match` refers to the state of an event that is identified as either egamma or background. It is 1 if the event is egamma and 0 otherwise. Similarly, the label `isEG` refers to egamma events, and the label `isPU` refers to background events.\n", "\n", "Now that we have the dataset, let's go ahead and plot everything. We can make the classic color choice that blue is signal and red is background. Our goal in the end will be to use all of the variables that we have selected in the dataset to separate blue from red. This is a large multidimensional problem, and so you can see why it would be hard for us to just simply select cuts on parameters by hand. \n", "\n", "Here, we really need to come up with an automated scheme, and this is what pytorch helps us with."]}, {"cell_type": "code", "execution_count": null, "id": "233f2c5d", "metadata": {"scrolled": false, "tags": ["learner", "py", "lect_02", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.2-runcell02\n", "\n", "col_names = list(df.columns)\n", "print(col_names)\n", "\n", "fig, axs = plt.subplots(len(col_names),1,figsize=(4,4*len(col_names)))\n", "for ix,ax in enumerate(axs):\n", "    ax.hist(df[col_names[ix]][df['gen_match']==0],bins=np.linspace(np.min(df[col_names[ix]]),np.max(df[col_names[ix]]),20),histtype='step',color='r',density=True)\n", "    ax.hist(df[col_names[ix]][df['gen_match']==1],bins=np.linspace(np.min(df[col_names[ix]]),np.max(df[col_names[ix]]),20),histtype='step',color='b',density=True)\n", "    ax.set_xlabel(col_names[ix])\n", "\n", "plt.show()"]}, {"cell_type": "markdown", "id": "1c95c4a6", "metadata": {"tags": ["learner", "md", "lect_02"]}, "source": ["Note in particular the last three plots. As discussed above and in the video, `isPU` indicates whether a particular event is background and `isEG` indicates whether it is egamma. So, the good events (blue histograms) would have `isPU=0` (i.e. not background) and `isEG=1` (i.e. an egamma event). For this particular simulation, `isEG` and `gen match` flag the same events.\n", "\n", "The other thing to remind ourselves of is that many of these variables can be correlated. What that means is that when we select on one variable, we are potentially also indirectly selecting on another. The network can recognize this and attempt to \"decorrelate\" variables to get better performance. Sometimes it's too good at this and makes our problem more difficult."]}, {"cell_type": "markdown", "id": "22c8d077", "metadata": {"tags": ["learner", "md", "lect_02"]}, "source": ["<h3>Simple Regression Network</h3>\n", "\n", "Let's make a simple logistic regression network on this data to differentiate between background data (labeled as PU) and egamma events (EG).\n", "\n", "\n", "\n", "An important component of training a neural network is preparing the input. It is typical to split the data you have into different sets, with the most common three being: \"training\", \"testing\", and \"validation\". Here we use 30% of the data for testing and 70% for training and validation, with that 70% of the data split into 50%/20% for training/validation.\n", "\n", "The reason for each is: \n", "\n", " * Training : This the dataset that we use to adjust the parameters within the network to most accurately select the events we want.\n", " * Validation : This is a dataset that we use while training to check that our loss is the same or similar on independent data. It can also be used for tuning the so-called \"hyperparameters\", variables which control how the training proceeds.\n", " * Testing : This is the dataset that we use to compute the performance of the algorithm.\n", " \n", "Let's go ahead and make these three separate datasets. It will be clear how we use them in a sec. Note that PyTorch uses `dataloaders` which help handle batching, etc.  \n"]}, {"cell_type": "code", "execution_count": null, "id": "0fb25db6", "metadata": {"tags": ["learner", "py", "lect_02", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.2-runcell03\n", "\n", "\n", "dataset = df.values\n", "\n", "X = dataset[:,4:-3]\n", "#last 3 columns are labels\n", "ninputs = len(list(df.columns))-3-4\n", "\n", "Y = dataset[:,-1:]\n", "#last column will be used for the label\n", "\n", "test_frac = 0.3\n", "val_frac = 0.2\n", "\n", "alldataset = torch.utils.data.TensorDataset(torch.tensor(X, dtype=torch.float32), torch.tensor(Y, dtype=torch.float32))\n", "\n", "torch.random.manual_seed(42) # fix a random seed for reproducibility\n", "testdataset, trainvaldataset = torch.utils.data.random_split(\n", "    alldataset, [int(len(Y)*test_frac),\n", "              int(len(Y)*(1-test_frac))])\n", "\n", "torch.random.manual_seed(42) # fix a random seed for reproducibility\n", "traindataset, valdataset = torch.utils.data.random_split(\n", "    trainvaldataset, [int(len(Y)*(1.-test_frac)*(1.-val_frac)),\n", "              int(len(Y)*(1.-test_frac)*val_frac)])\n", "\n", "testloader = torch.utils.data.DataLoader(testdataset,\n", "                                          num_workers=6,\n", "                                          batch_size=500,\n", "                                          shuffle=False)\n", "trainloader = torch.utils.data.DataLoader(traindataset,\n", "                                          num_workers=6,\n", "                                          batch_size=500,\n", "                                          shuffle=True)\n", "valloader = torch.utils.data.DataLoader(valdataset,\n", "                                        num_workers=6,\n", "                                        batch_size=500,\n", "                                        shuffle=False)\n"]}, {"cell_type": "markdown", "id": "5af8514f", "metadata": {"tags": ["learner", "md", "lect_02"]}, "source": ["Now, we need to define our network architecture and the connections. Let's start with the kind of logistic regression network we saw already. This will be a 1-layer network. We will take in the number of inputs and then run our sigmoid function on the outputs, like we did before. \n", "\n", "PyTorch requires that we first define the layers we want to use in `__init__()` (here we build using standard library layers), and then we define the connection in `forward()`. The input `x` is first passed through the fully connected layer, `self.fc1` with input size `ninputs`, and then through the sigmoid activation function, and the output of size 1 is returned. This setup will allow PyTorch to construct the backward pass automatically although, for more complex or specialized networks, it is possible to define the backward pass manually."]}, {"cell_type": "code", "execution_count": null, "id": "54a15188", "metadata": {"tags": ["learner", "py", "lect_02", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.2-runcell04\n", "\n", "class LR_net(torch.nn.Module):\n", "    def __init__(self):\n", "        super().__init__()\n", "        self.fc1 = torch.nn.Linear(ninputs,1)\n", "        self.output = torch.nn.Sigmoid()\n", "\n", "    def forward(self, x):\n", "        x = self.fc1(x)\n", "        x = self.output(x)\n", "        return x\n", "        \n", "torch.random.manual_seed(42)  # fix a random seed for reproducibility\n", "\n", "model_lr = LR_net()\n", "print(model_lr)\n", "print('----------')\n", "print(model_lr.state_dict())"]}, {"cell_type": "markdown", "id": "3f523bdf", "metadata": {"tags": ["learner", "md", "lect_02"]}, "source": ["When the neural network is created, the code randomly generates initial values for all of the parameters, in roughly the range of +/-0.25 for this case . The `torch.random.manual_seed` line is used to guarantee the same random set is chosen every time, a feature which will be important for reproducibility when answering some of the later exercises."]}, {"cell_type": "markdown", "id": "ac90e900", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_14_2'></a>     \n", "\n", "| [Top](#section_14_0) | [Restart Section](#section_14_2) | [Next Section](#section_14_3) |\n"]}, {"cell_type": "markdown", "id": "13f2d256", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-14.2.1</span>\n", "\n", "Consider the variables that you plotted in `L14.2-runcell02`. Among the following variables, which appear to have high discrimination power? In other words, in which plots is the background (red) distinguishable from the egamma (blue), meaning there is a relatively small overlap between the red and blue histograms? Select all that apply.\n", "\n", "A) pt\\\n", "B) eta\\\n", "C) phi\\\n", "D) energy\\\n", "E) e2x2\\\n", "F) sihih\n"]}, {"cell_type": "markdown", "id": "69f30ae9", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-14.2.2</span>\n", "\n", "How are training, validation, and testing data used in machine learning model development?\n", "\n", "A) Training data is used to evaluate the model's performance, validation data is used to select the best hyperparameters, and testing data is used to train the model.\\\n", "B) Training data is used to train the model, validation data is used to tune the hyperparameters, and testing data is used to evaluate the model's performance.\\\n", "C) Training data is used to tune the hyperparameters, validation data is used to evaluate the model's performance, and testing data is used to train the model.\\\n", "D) All three datasets are used interchangeably to train, tune, and evaluate the model."]}, {"cell_type": "markdown", "id": "e9d7add9", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-14.2.3</span>\n", "\n", "In the one-layer neural network that we have defined in this section (`LR_net` from `L14.2-runcell04`), we are using 19 input features. How many weights does this neural network have? Enter your answer as an integer.\n", "\n", "Extra: How is this different from the two-weight model we were using in the last Lesson?"]}, {"cell_type": "markdown", "id": "1d1630a3", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_14_3'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L14.3 Training and Testing the Network</h2>  \n", "\n", "| [Top](#section_14_0) | [Previous Section](#section_14_2) | [Exercises](#exercises_14_3) | [Next Section](#section_14_4) |\n"]}, {"cell_type": "markdown", "id": "507349e2", "metadata": {"tags": ["learner", "md"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.2x+1T2025/block-v1:MITxT+8.S50.2x+1T2025+type@sequential+block@seq_LS14/block-v1:MITxT+8.S50.2x+1T2025+type@vertical+block@vert_LS14_vid3\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "id": "89852a6f", "metadata": {"tags": ["learner", "md", "lect_03"]}, "source": ["<h3>Overview</h3>\n", "\n", "Now let's train! We do this using the `Adam` optimizer and binary cross entropy loss (as before). We don't need to write out the formulae. We can just declare the loss from a loss function and an optimizer. In this training, we will also post the losses for the validation data. We want these to be similar to the regular loss found during the training. In fact, they should be statistically similar. \n", "\n", "**NOTE:** This could take a little time, depending on your computing resources."]}, {"cell_type": "code", "execution_count": null, "id": "eaa7ff3f", "metadata": {"tags": ["learner", "py", "lect_03", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.3-runcell01\n", "\n", "criterion = torch.nn.BCELoss()\n", "optimizer_lr = torch.optim.Adam(model_lr.parameters(), lr=0.003) \n", "\n", "history_lr = {'loss':[], 'val_loss':[]}\n", "\n", "for epoch in range(20):\n", "\n", "    current_loss = 0.0 #rezero loss\n", "    \n", "    for i, data in enumerate(trainloader):\n", "\n", "        inputs, labels = data\n", "        \n", "        # zero the parameter gradients\n", "        optimizer_lr.zero_grad()\n", "\n", "        # forward + backward + optimize (training magic)\n", "        # This will use the pytorch autograd feature to adjust the\n", "        ## parameters of our function to minimize the loss\n", "        outputs = model_lr(inputs)\n", "        loss = criterion(outputs, labels)\n", "        loss.backward()\n", "        optimizer_lr.step()\n", "        \n", "        # add loss statistics\n", "        current_loss += loss.item()\n", "        \n", "        if i == len(trainloader)-1:\n", "            current_val_loss = 0.0\n", "            with torch.no_grad():#disable updating gradient\n", "                for iv, vdata in enumerate(valloader):\n", "                    val_inputs, val_labels = vdata\n", "                    val_loss = criterion(model_lr(val_inputs), val_labels)\n", "                    current_val_loss += val_loss.item()\n", "            print('[%d, %4d] loss: %.4f  val loss: %.4f' % \n", "                  (epoch + 1, i + 1, current_loss/float(i+1) , current_val_loss/float(len(valloader))))\n", "\n", "            history_lr['loss'].append(current_loss/float(i+1))\n", "            history_lr['val_loss'].append(current_val_loss/float(len(valloader)))\n", "            \n", "print('Finished Training')\n", "torch.save(model_lr.state_dict(), 'data/L14/lr_model.pt')\n", "print(model_lr.state_dict())"]}, {"cell_type": "markdown", "id": "389636d9", "metadata": {"tags": ["learner", "md", "lect_03"]}, "source": ["Ok, how is the training doing? Let's visualize the evolution of the loss by epoch."]}, {"cell_type": "code", "execution_count": null, "id": "f2504550", "metadata": {"tags": ["learner", "py", "lect_03", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.3-runcell02\n", "\n", "plt.semilogy(history_lr['loss'], label='loss')\n", "plt.semilogy(history_lr['val_loss'], label='val_loss')\n", "plt.legend(loc=\"upper right\")\n", "plt.xlabel('epoch')\n", "plt.ylabel('loss (binary crossentropy)')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "f6256331", "metadata": {"tags": ["learner", "md", "lect_03"]}, "source": ["We start to see that our loss is converging, although it looks like more epochs might give an even better result.  Importantly, we also see that our validation and regular losses are similar. Interestingly, the validation loss could be \"better\" that the training loss. We address that point below.\n", "\n", "Sometimes, overtraining can occur. This is when the sensitivity starts to exceed the statistical precision of the dataset and we start training on random fluctuation features in the data. When overtraining occurs, the network starts to isolate features specific to the training dataset which are not present in the validation data, and the two loss values start to deviate from each other. \n"]}, {"cell_type": "markdown", "id": "86c4c763", "metadata": {"tags": ["learner", "md", "lect_03"]}, "source": ["<h3>Tuning the Training</h3>\n", "\n", "How do we prevent overtraining? Let's define a \"stopping criteria\" by using the validation loss. We will stop the training if the validation loss appears to have hit its minimum, but we will let the training run for a few more epochs to allow for the possibility of a local minimum or single-epoch spikes. There are other ways to define an early stopping criterion, but we will use this technique for now. The code cell below just defines everything that is needed, but does not actually run the training. Also note that it uses the final parameter values found at the end of the previous 20 epochs as starting values. If you want to start completely from scratch, rerun code cell `L14.2-runcell04` before running the code cells below. "]}, {"cell_type": "code", "execution_count": null, "id": "94538aef", "metadata": {"tags": ["learner", "py", "lect_03", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.3-runcell03\n", "\n", "def train(model,trainloader,valloader,nepochs=100,lr=0.003,l2reg=0.,patience=5,name=None):\n", "\n", "    criterion = torch.nn.BCELoss()\n", "    \n", "    #NOTE: l2 regularization is set to 0 by default,\n", "    #but we will address this in later sections\n", "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2reg) \n", "\n", "    history = {'loss':[], 'val_loss':[]}\n", "\n", "    min_loss = 999999.\n", "    min_epoch = 0\n", "    min_model = model.state_dict()\n", "    should_stop = False\n", "    \n", "    for epoch in range(nepochs):\n", "\n", "        current_loss = 0.0 #rezero loss\n", "\n", "        for i, data in enumerate(trainloader):\n", "\n", "            inputs, labels = data\n", "\n", "            # zero the parameter gradients\n", "            optimizer.zero_grad()\n", "\n", "            # forward + backward + optimize\n", "            # This will use the pytorch autograd feature to adjust the\n", "            ## parameters of our function to minimize the loss\n", "            outputs = model(inputs)\n", "            loss = criterion(outputs, labels)\n", "            loss.backward()\n", "            optimizer.step()\n", "\n", "            # print statistics\n", "            current_loss += loss.item()\n", "\n", "            if i == len(trainloader)-1:\n", "                current_val_loss = 0.0\n", "                with torch.no_grad():#disable updating gradient\n", "                    model.eval() #place model in evaluation state\n", "                                ## necessary for some layer types (like dropout)\n", "                    for iv, vdata in enumerate(valloader):\n", "                        val_inputs, val_labels = vdata\n", "                        val_loss = criterion(model(val_inputs), val_labels)\n", "                        current_val_loss += val_loss.item()\n", "                    model.train() #return to training state\n", "                current_loss = current_loss/float(i+1)\n", "                current_val_loss = current_val_loss/float(len(valloader))\n", "                print('[%d, %4d] loss: %.4f  val loss: %.4f' % \n", "                      (epoch + 1, i + 1, current_loss , current_val_loss))\n", "\n", "                if current_val_loss < min_loss:\n", "                    min_loss = current_val_loss\n", "                    min_model = model.state_dict()\n", "                    min_epoch = epoch\n", "                elif epoch-min_epoch==5:\n", "                    model.load_state_dict(min_model)\n", "                    should_stop = True\n", "                    break\n", "\n", "                history['loss'].append(current_loss)\n", "                history['val_loss'].append(current_val_loss)\n", "                \n", "            if should_stop:\n", "                break\n", "\n", "    print('Finished Training')\n", "    if name is not None:\n", "        filename_save = 'data/L14/' + name + '.pt'\n", "        torch.save(model.state_dict(), filename_save)\n", "    return history"]}, {"cell_type": "markdown", "id": "bfb2b7b6", "metadata": {"tags": ["learner", "md", "lect_03"]}, "source": ["Let's now run for a number of epochs and see if we get to a point where the training stops."]}, {"cell_type": "code", "execution_count": null, "id": "bd675e99", "metadata": {"tags": ["learner", "py", "lect_03", "learner_chopped"]}, "outputs": [], "source": ["history_lr = train(model_lr,trainloader,valloader,name='lr_model')"]}, {"cell_type": "markdown", "id": "d6e56782", "metadata": {"tags": ["learner", "md", "lect_03"]}, "source": ["Like before, we can also make a plot of the evolution to see if our loss values are behaving the way we expect, and also to  make a judgement on what is going on. "]}, {"cell_type": "code", "execution_count": null, "id": "701bc6af", "metadata": {"tags": ["learner", "py", "lect_03", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.3-runcell04\n", "\n", "plt.semilogy(history_lr['loss'], label='loss')\n", "plt.semilogy(history_lr['val_loss'], label='val_loss')\n", "plt.legend(loc=\"upper right\")\n", "plt.xlabel('epoch')\n", "plt.ylabel('loss (binary crossentropy)')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "66fff44e", "metadata": {"tags": ["learner", "md", "lect_03"]}, "source": ["As you can see, the training continued until it appeared that either the validation loss had hit a minimum (and then stopped a few epochs later) or until 100 epochs had been run."]}, {"cell_type": "markdown", "id": "a6c1bf3f", "metadata": {"tags": ["learner", "md", "lect_03"]}, "source": ["<h3>Applying to Testing Data</h3>\n", "\n", "Now let's see what happens when we apply this set of network parameters to our test data. This is essentially the same setup we used for the validation data. However, in this case, we are looking at data which was never considered during the training."]}, {"cell_type": "code", "execution_count": null, "id": "e588d00b", "metadata": {"tags": ["learner", "py", "lect_03", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.3-runcell05\n", "\n", "def apply(model, testloader):\n", "    with torch.no_grad():\n", "        model.eval()\n", "        outputs = []\n", "        labels = []\n", "        for data in testloader:\n", "            test_inputs, test_labels = data\n", "            outputs.append(model(test_inputs).numpy())\n", "            labels.append(test_labels.numpy())\n", "        model.train()\n", "\n", "        Y_test_predict = outputs\n", "        Y_test = labels\n", "\n", "    Y_test_predict = np.concatenate(Y_test_predict)\n", "    Y_test = np.concatenate(Y_test)\n", "    \n", "    return Y_test_predict,Y_test\n", "\n", "Y_test_predict_lr, Y_test = apply(model_lr, testloader)\n", "\n", "print(Y_test_predict_lr.shape)\n", "print(Y_test.shape)"]}, {"cell_type": "markdown", "id": "cc1767c7", "metadata": {"tags": ["learner", "md", "lect_03"]}, "source": ["And now let's plot the distribution of the output of the network. "]}, {"cell_type": "code", "execution_count": null, "id": "de486bc7", "metadata": {"tags": ["learner", "py", "lect_03", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.3-runcell06\n", "\n", "plt.hist(Y_test_predict_lr[Y_test==0],histtype='step',color='r',density=True)\n", "plt.hist(Y_test_predict_lr[Y_test==1],histtype='step',color='b',density=True)\n", "plt.xlabel('Logistic Regression Discriminant')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "36e5ea8f", "metadata": {"tags": ["learner", "md", "lect_03"]}, "source": ["As we wanted, the background (red) is peaked at 0, while the EG (blue) is closer to 1. "]}, {"cell_type": "markdown", "id": "a16ea19d", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_14_3'></a>     \n", "\n", "| [Top](#section_14_0) | [Restart Section](#section_14_3) | [Next Section](#section_14_4) |\n"]}, {"cell_type": "markdown", "id": "aaa7b696", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-14.3.1</span>\n", "\n", "Which of the following features indicates that training is NOT performing successfully? Select all that apply:\n", "\n", "A) The loss for the validation data differs significantly from that for the training data.\\\n", "B) The loss as a function of epoch flattens out for both data sets.\\\n", "C) The loss as a function of epoch is shifted slightly for the validation data compared to the training data.\\\n", "D) The loss as a function of epoch continues to decrease for the training data set, but remains constant for the validation data set."]}, {"cell_type": "markdown", "id": "293d15d7", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-14.3.2</span>\n", "\n", "We can approximate the uncertainty on the loss by assuming that the number of events in both datasets follows a Poisson distribution. Using this concept, complete the code below to calculate the statistical disagreement between the training loss and validation loss. Specifically, write a function that returns the difference between the losses in terms of the number of standard deviations.\n", "\n", "**Extra:** How significant is the difference after the last epoch? Try plotting this as a function of epoch!\n", "\n", "**Note:** The related plot may yield wildly different results, depending on how your network runs. Here we focus on how to write the function, instead of analyzing the output of the plot."]}, {"cell_type": "code", "execution_count": null, "id": "50324d40", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L14.3.2\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def num_stdev(iNTrain,iNVal,loss1_array, loss2_array):\n", "    #convert from list to array\n", "    loss1_array = np.array(loss1_array)\n", "    loss2_array = np.array(loss2_array)\n", "    \n", "    sigma_loss1 = #YOUR CODE HERE (the stdev of the training loss)\n", "    sigma_loss2 = #YOUR CODE HERE (the stdev of the validation loss)\n", "    \n", "    #the combined uncertainty\n", "    sigma_tot = np.sqrt(sigma_loss1**2. + sigma_loss2**2.) \n", "    \n", "    #the difference in losses\n", "    delta = loss2_array-loss1_array\n", "    \n", "    #calculate the difference in terms of number of standard deviations\n", "    diff = abs(delta/sigma_tot) \n", "    \n", "    return diff\n", "\n", "#plot\n", "#----------------------------------------------------\n", "N_train = len(trainloader)*trainloader.batch_size\n", "N_val   = len(valloader)*valloader.batch_size #the number of rows in the data set\n", "diff_sig = num_stdev(N_train,N_val,history_lr['loss'], history_lr['val_loss'])\n", "print(\"Significance of last epoch\",diff_sig[-1])\n", "\n", "\n", "plt.plot(np.arange(len(diff_sig)),diff_sig)\n", "plt.xlabel(\"N-iteration\")\n", "plt.ylabel(\"(train-test)/$\\sigma$\")\n", "plt.show()"]}, {"cell_type": "markdown", "id": "87e047a0", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-14.3.3</span>\n", "\n", "A common way to select events based on a particular final discriminator value from the neural network, is to make normalized histograms (i.e. histograms with the same integral), as is done in the previous examples, and then to select only events above the line where the signal and background histograms cross. For the histogram produced by code cell `L14.3-runcell06`, what fraction of egamma events (blue) or background (red) are above the bin of intersection (you should see this intersection occur at a value of `intersection_bin = 0.20`)?\n", "\n", "Report your answer as a list of numbers with precision 1e-2: `[frac EG, frac PU]`\n"]}, {"cell_type": "code", "execution_count": null, "id": "93aca6a3", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L14.3.3\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "#determine fraction of events above intersection\n", "intersection_bin = 0.20\n", "EG_frac = #YOUR CODE HERE\n", "PU_frac = #YOUR CODE HERE\n", "\n", "print(\"EG\", EG_frac)\n", "print(\"PU:\", PU_frac)"]}, {"cell_type": "markdown", "id": "892f0941", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": [">#### Follow-up 14.3.3a (ungraded)\n", ">\n", ">Define a two-weight network, as we had in the last Lesson, and run the training of your two-weight network on the data. What do the resulting weights look like? Can you make a 1D histogram of the separation? Play with the smearing parameter, how do things change?\n", ">\n", ">**NOTE:** Be sure to label your classes, functions, and outputs differently. We will continue to use the results from above, so do not get your previous results confused with your results from this follow-up exercise!"]}, {"cell_type": "code", "execution_count": null, "id": "c59b2ab7", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L14.3.3a\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "class LR_net_2(torch.nn.Module):\n", "    #YOUR CODE HERE\n", "\n", "        \n", "model_lr_2 = LR_net_2()\n", "print(model_lr_2)\n", "print('----------')\n", "print(model_lr_2.state_dict())\n", "\n", "\n", "#-----------------\n", "#TRAIN THE NETWORK\n", "#YOUR CODE HERE"]}, {"cell_type": "markdown", "id": "b32c3d56", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_14_4'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L14.4 Adding a Hidden Layer</h2>     \n", "\n", "| [Top](#section_14_0) | [Previous Section](#section_14_3) | [Exercises](#exercises_14_4) | [Next Section](#section_14_5) |\n"]}, {"cell_type": "markdown", "id": "eb2225fd", "metadata": {"tags": ["learner", "md"]}, "source": ["*The material in this section is discussed in the video **<a href=\"https://courses.mitxonline.mit.edu/learn/course/course-v1:MITxT+8.S50.2x+1T2025/block-v1:MITxT+8.S50.2x+1T2025+type@sequential+block@seq_LS14/block-v1:MITxT+8.S50.2x+1T2025+type@vertical+block@vert_LS14_vid4\" target=\"_blank\">HERE</a>.** You are encouraged to watch that video and use this notebook concurrently.*"]}, {"cell_type": "markdown", "id": "59cccf2d", "metadata": {"tags": ["learner", "md", "lect_04"]}, "source": ["<h3>Overview</h3>\n", "\n", "What we did above was a small 1-layer network and really not representative of the power of deep learning. Instead of just a few weights, let's now pump up the number of free parameters by adding a variety of layers. This will allow us to be much more expressive in the way we can discriminate events. Details of exactly what is added to the neural network in the code below is described in the video. Let's start by declaring the updated model."]}, {"cell_type": "code", "execution_count": null, "id": "252a28eb", "metadata": {"tags": ["learner", "py", "lect_04", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.4-runcell01\n", "\n", "class MLP2_net(torch.nn.Module):\n", "    def __init__(self):\n", "        super().__init__()\n", "        self.fc1 = torch.nn.Linear(ninputs,30)\n", "        self.act1 = torch.nn.ReLU()\n", "        self.fc2 = torch.nn.Linear(30,10)\n", "        self.act2 = torch.nn.ReLU()\n", "        self.fc3 = torch.nn.Linear(10,1)\n", "        self.output = torch.nn.Sigmoid()\n", "\n", "    def forward(self, x):\n", "        x = self.fc1(x)\n", "        x = self.act1(x)\n", "        x = self.fc2(x)\n", "        x = self.act2(x)\n", "        x = self.fc3(x)\n", "        x = self.output(x)\n", "        return x\n", "    \n", "torch.random.manual_seed(42)  # fix a random seed for reproducibility\n", "\n", "model_mlp_2layer = MLP2_net()\n", "print(model_mlp_2layer)"]}, {"cell_type": "markdown", "id": "3615f24d", "metadata": {"tags": ["learner", "md", "lect_04"]}, "source": ["Now, we can go ahead and train. Pay attention to the loss value compared to before, you should already start to see signs that the performance is better because we have now made the model much more flexible by adding a second layer. Let's run the training. "]}, {"cell_type": "code", "execution_count": null, "id": "e526d8b1", "metadata": {"tags": ["learner", "py", "lect_04", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.4-runcell02\n", "\n", "history_mlp_2layer = train(model_mlp_2layer,trainloader,valloader,name='mlp_2layer_model')\n", "Y_test_predict_mlp_2layer, Y_test = apply(model_mlp_2layer, testloader)"]}, {"cell_type": "markdown", "id": "c735d5a1", "metadata": {"tags": ["learner", "md", "lect_04"]}, "source": ["Like we did before, we can again go ahead and scan our training to make sure the loss is close to convergence and we haven't overtrained. "]}, {"cell_type": "code", "execution_count": null, "id": "aba3384f", "metadata": {"tags": ["learner", "py", "lect_04", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.4-runcell03\n", "\n", "plt.semilogy(history_mlp_2layer['loss'], label='loss')\n", "plt.semilogy(history_mlp_2layer['val_loss'], label='val_loss')\n", "plt.legend(loc=\"upper right\")\n", "plt.xlabel('epoch')\n", "plt.ylabel('loss (binary crossentropy)')\n", "plt.show()\n", "\n", "plt.hist(Y_test_predict_mlp_2layer[Y_test==0],histtype='step',color='r',density=True)\n", "plt.hist(Y_test_predict_mlp_2layer[Y_test==1],histtype='step',color='b',density=True)\n", "plt.xlabel('MLP (2 hidden layers) Discriminant')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "11224510", "metadata": {"tags": ["learner", "md", "lect_04"]}, "source": ["We can check the signal and background efficiencies based on their distributions versus discriminant value. Compared to the plot generated by code cell `L14.3-runcell06`, there appears to be a dramatic improvement! The tail of the background histogram is much lower, and the signal histogram is now peaked at 1. So, it looks like we are keeping more signal and getting more background rejection. As a quantitative check, let's repeat what we did in `Ex-14.3.3`. However, since the two histograms now cross at 0.1, let's extract the integrated values above that bin."]}, {"cell_type": "code", "execution_count": null, "id": "cabab175", "metadata": {"tags": ["learner", "py", "lect_04", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.4-runcell04\n", "\n", "print(\"Signal\",len(Y_test_predict_mlp_2layer[Y_test==1][Y_test_predict_mlp_2layer[Y_test==1] > 0.10])/len(Y_test_predict_mlp_2layer[Y_test==1]))\n", "print(\"Big:\"  ,len(Y_test_predict_mlp_2layer[Y_test==0][Y_test_predict_mlp_2layer[Y_test==0] > 0.10])/len(Y_test_predict_mlp_2layer[Y_test==0]))"]}, {"cell_type": "markdown", "id": "11877d39", "metadata": {"tags": ["learner", "md", "lect_04"]}, "source": ["<h3>Plotting the ROC</h3>\n", "\n", "This does look better than the logistic regression. But how would we establish that improvement in more detail? A Receiver Operating Characteristic (ROC) curve is a typical way to compare multiple algorithms. Basically, we are going to make a requirement on the neural network output: if it is below a given value we will call it background, and if it is above that value it's EG. We can scan this cutoff value between 0 and 1 and then plot the fraction of background and signal at each point, thereby quantifying how well a particular cutoff predicts the correct labels. \n", "\n", "\n", "More specifically, we can define two axes for the ROC as \n", "\n", " * $\\epsilon_{s}=\\int_{-\\infty}^{x} {\\rm Disc}(x|x_{i}\\in{\\rm Signal}) dx$\n", " * $\\epsilon_{b}=\\int_{-\\infty}^{x} {\\rm Disc}(x|x_{i}\\in{\\rm Background}) dx$"]}, {"cell_type": "code", "execution_count": null, "id": "e9460713", "metadata": {"tags": ["learner", "py", "lect_04", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L14.4-runcell05\n", "\n", "def compute_ROC(labels, predicts, npts=101):\n", "    cutvals = np.linspace(0.,1.,num=npts)\n", "    tot0 = float(len(labels[labels==0]))\n", "    tot1 = float(len(labels[labels==1]))\n", "    tpr = []\n", "    fpr = []\n", "    for c in cutvals:\n", "        fpr.append(float(len(predicts[(labels==0) & (predicts>c)]))/tot0)\n", "        tpr.append(float(len(predicts[(labels==1) & (predicts>c)]))/tot1)\n", "    \n", "    return np.array(fpr),np.array(tpr)\n", "\n", "mlp_2layer_rocpts = compute_ROC(Y_test,Y_test_predict_mlp_2layer)\n", "lr_rocpts = compute_ROC(Y_test,Y_test_predict_lr)\n", "\n", "plt.plot(mlp_2layer_rocpts[0],mlp_2layer_rocpts[1],'g-',label=\"MLP (2 hidden layers)\")\n", "plt.plot(lr_rocpts[0],lr_rocpts[1],'m--',label=\"Logistic Regression\")\n", "plt.title(\"ROC (Receiver Operating Characteristic) Curve\")\n", "plt.xlabel(\"False Positive Rate (FPR) aka Background Efficiency\")\n", "plt.ylabel(\"True Positive Rate (TPR) aka Signal Efficiency\")\n", "plt.legend(loc=\"lower right\")\n", "plt.show()"]}, {"cell_type": "markdown", "id": "26379b16", "metadata": {"tags": ["learner", "md", "lect_04"]}, "source": ["Reading a ROC can take a second if you haven't seen one before. The horizontal and vertical axes show the fraction of the background and signal, respectively, that are accepted for different values of the discriminant cut. The fixed endpoints at (1,1) and (0,0) (which are identical for any model) represent the trivial cases of accepting or rejecting all events, respectively.\n", "\n", "The key is usually to find an algorithm that gets as close as possible to the **top left corner**, since that represents rejecting more background (moving to the left) with higher efficiency for the signal (moving up). As you can see by looking at this top left corner, the model with hidden layers does do better than the earlier logistic regression.\n", "\n", "**Note:** The \"background efficiency\" and \"false positive rate\" mean the same thing. They are oppositely related to the \"background rejection rate,\" which is the the percentage of background events that are rejected. In other words, a background efficiency of 0.03 is equal to a background rejection rate of 0.97.\n", "\n", "However, picking a specific point on the curve to use in the data analysis (sometimes called the \"operating\" point) is not always as simple as being as close as possible to the top left corner. For example, if the background appears as a relatively smooth distribution underlying a narrow signal peak, it may be acceptable to include more background in order to take advantage of the corresponding increase in signal efficiency. In other words, one would move the operating point up and to the right on the curve. Alternatively, if it's necessary to maximally reduce the background, and the dataset has more than enough signal events, the operating point would be moved in the opposite direction."]}, {"cell_type": "markdown", "id": "96231368", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_14_4'></a>   \n", "\n", "| [Top](#section_14_0) | [Restart Section](#section_14_4) | [Next Section](#section_14_5) |\n"]}, {"cell_type": "markdown", "id": "37c7fb43", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-14.4.1</span>\n", "\n", "When we compare the performance of two algorithms, we often like to fix the signal efficiency and look at the change in the background rejection rate. For a fixed signal efficiency of 97%, what is the fractional reduction in the false-positive rate between the logistic and MLP networks (i.e. the difference between the two divided by the value for the logistic)? Report your answer as a number with precision 5e-2."]}, {"cell_type": "code", "execution_count": null, "id": "0845f595", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L14.4.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "\n", "def frac_reduc_fpr(lr_rocpts, mlp_2layer_rocpts, sig_eff=0.97):\n", "    #false-positive-rate (background efficiency)\n", "    #true-positive-rate (signal efficiency):\n", "    lr_fpr = lr_rocpts[0]\n", "    lr_tpr = lr_rocpts[1]\n", "    mlp_2layer_fpr = mlp_2layer_rocpts[0]\n", "    mlp_2layer_tpr = mlp_2layer_rocpts[1]\n", "    \n", "    #find lr_fpr where lr_tpr is closest to sig_eff\n", "    lr_fpr_val = #YOUR CODE HERE\n", "    \n", "    #find mlp_2layer_fpr where lr_tpr is closest to sig_eff\n", "    mlp_2layer_fpr_val = #YOUR CODE HERE\n", "    \n", "    #calculate the fractional reduction in false-positive-rate\n", "    frac_red = #YOUR CODE HERE\n", "    \n", "    return frac_red\n", "\n", "#find where the signal efficiency is 97%\n", "#find difference in logistic vs. MLP\n", "print(\"Fractional Reduction in FPR:\",frac_reduc_fpr(lr_rocpts, mlp_2layer_rocpts, 0.97))"]}, {"cell_type": "markdown", "id": "d11a16fc", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_14_5'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L14.5 Regularization, Batch Normalization, and Dropout</h2>     \n", "\n", "| [Top](#section_14_0) | [Previous Section](#section_14_4) | [Exercises](#exercises_14_5) |\n"]}, {"cell_type": "markdown", "id": "bedb9016", "metadata": {"tags": ["learner", "md", "lect_05"]}, "source": ["<h3>Regularization and Network Tuning</h3>\n", "\n", "*Note: There is no corresponding video for this section.*\n", "\n", "The 2-layer MLP we made does indeed do better, especially if we want to reject as much as possible of the background.\n", "\n", "Let's try an even larger network with additional layers. Also, as discussed below, we'll add some other techniques to our network in order to further improve the quality of our training. "]}, {"cell_type": "code", "execution_count": null, "id": "b60a0696", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_05"]}, "outputs": [], "source": ["#>>>RUN: L14.5-runcell01\n", "\n", "class MLP3_net(torch.nn.Module):\n", "    def __init__(self):\n", "        super().__init__()\n", "        self.fc1 = torch.nn.Linear(ninputs,50)\n", "        self.act1 = torch.nn.ReLU()\n", "        self.fc2 = torch.nn.Linear(50,30)\n", "        self.act2 = torch.nn.ReLU()\n", "        self.fc3 = torch.nn.Linear(30,10)\n", "        self.act3 = torch.nn.ReLU()\n", "        self.fc4 = torch.nn.Linear(10,1)\n", "        self.output = torch.nn.Sigmoid()\n", "\n", "    def forward(self, x):\n", "        x = self.fc1(x)\n", "        x = self.act1(x)\n", "        x = self.fc2(x)\n", "        x = self.act2(x)\n", "        x = self.fc3(x)\n", "        x = self.act3(x)\n", "        x = self.fc4(x)\n", "        x = self.output(x)\n", "        return x\n", "    \n", "torch.random.manual_seed(42)  # fix a random seed for reproducibility\n", "model_mlp_3layer = MLP3_net()\n", "print(model_mlp_3layer)"]}, {"cell_type": "markdown", "id": "0d0abb78", "metadata": {"tags": ["learner", "md", "lect_05"]}, "source": ["<h3>Regularization</h3>\n", "\n", "Let's also try to use a form of regularization, in this case L2. If left unchecked, larger networks especially can begin to find and abuse certain subtle features that we perhaps don't want them to. The obvious case is if the feature is a statistical glitch only present in the training set. In such a situation, we would be hurting ourselves by focusing on \"fitting\" that. L2 regularization adds a \"penalty term\" to the loss function, which is a function of the magnitude squared of the weight values. \n", "\n", "$$\\mathcal{L} = \\mathcal{L}_\\textrm{BCE} + \\lambda\\sum |W|^2$$\n", "\n", "We can control the relative importance of this term via the $\\lambda$ parameter. By encouraging the network to keep the weights small, it is less able to magnify the importance of one particular feature/node. In `pytorch`, this done by adding options to the optimizer. "]}, {"cell_type": "code", "execution_count": null, "id": "b0ca1ba8", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_05"]}, "outputs": [], "source": ["#>>>RUN: L14.5-runcell02\n", "\n", "# NOTE: we add the l2 regularization to the optimzer by setting l2reg=0.0001, which modifies the loss.\n", "# The l2 regularization is already implemented in the train() function, with default value l2reg=0.\n", "\n", "#you may choose to call the model again, if you have already run it\n", "#model_mlp_3layer.load_state_dict(torch.load('mlp_3layer_model.pt'))\n", "\n", "history_mlp_3layer = train(model_mlp_3layer,trainloader,valloader,l2reg=0.0001,name='mlp_3layer_model')\n", "Y_test_predict_mlp_3layer, Y_test = apply(model_mlp_3layer, testloader)"]}, {"cell_type": "code", "execution_count": null, "id": "df6a39b3", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_05"]}, "outputs": [], "source": ["#>>>RUN: L14.5-runcell03\n", "\n", "mlp_2layer_rocpts = compute_ROC(Y_test,Y_test_predict_mlp_2layer)\n", "mlp_3layer_rocpts = compute_ROC(Y_test,Y_test_predict_mlp_3layer)\n", "lr_rocpts = compute_ROC(Y_test,Y_test_predict_lr)\n", "\n", "plt.plot(mlp_2layer_rocpts[0],mlp_2layer_rocpts[1],'g-',label=\"MLP (2 hidden layers)\")\n", "plt.plot(mlp_3layer_rocpts[0],mlp_3layer_rocpts[1],'--',color='orange',label=\"MLP (3 hidden layers)\")\n", "plt.plot(lr_rocpts[0],lr_rocpts[1],'m--',label=\"Logistic Regression\")\n", "plt.title(\"ROC (Receiver Operating Characteristic) Curve\")\n", "plt.xlabel(\"False Positive Rate (FPR) aka Background Efficiency\")\n", "plt.ylabel(\"True Positive Rate (TPR) aka Signal Efficiency\")\n", "plt.legend(loc=\"lower right\")\n", "plt.show()"]}, {"cell_type": "markdown", "id": "fe1a092c", "metadata": {"tags": ["learner", "md", "lect_05"]}, "source": ["Hmmm... It's hard to see a dramatic improvement. However, perhaps a plot of the efficiencies of accepting signal and background ($\\epsilon_{s}$ and $\\epsilon_{b}$, respectively) is not the best way to evaluate the performance. Let's instead use $1/\\epsilon_{b}$ for the horizontal axis to really bring out the behavior for low background acceptance.\n", "\n", "In this new plot below, large values of $1/\\epsilon_{b}$ correspond to small values of background efficiency. Thus, these large values of $1/\\epsilon_{b}$ are also related to larger values of the background rejection rate. So, for a fixed value of signal efficiency, we would want a large value of $1/\\epsilon_{b}$.\n", "\n", "From this alternative way of plotting, you can see if there are very large gains in the background rejection rate, especially at lower signal efficiency. Recall that there can be experimental conditions where maximizing background rejection is the highest priority."]}, {"cell_type": "code", "execution_count": null, "id": "4556e191", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_05"]}, "outputs": [], "source": ["#>>>RUN: L14.5-runcell04\n", "\n", "mlp_2layer_rocpts = compute_ROC(Y_test,Y_test_predict_mlp_2layer,101)\n", "mlp_3layer_rocpts = compute_ROC(Y_test,Y_test_predict_mlp_3layer,101)\n", "lr_rocpts = compute_ROC(Y_test,Y_test_predict_lr,101)\n", "\n", "plt.plot(1./mlp_2layer_rocpts[0],mlp_2layer_rocpts[1],'g-',label=\"MLP (2 hidden layers)\")\n", "plt.plot(1./mlp_3layer_rocpts[0],mlp_3layer_rocpts[1],'--',color='orange',label=\"MLP (3 hidden layers)\")\n", "plt.plot(1./lr_rocpts[0],lr_rocpts[1],'m--',label=\"Logistic Regression\")\n", "plt.xlim([-1, 2500])\n", "plt.title(\"ROC (Receiver Operating Characteristic) Curve\")\n", "plt.xlabel(\"1/(Background Efficiency)\")\n", "plt.ylabel(\"True Positive Rate (TPR) aka Signal Efficiency\")\n", "plt.legend(loc=\"upper right\")\n", "plt.show()"]}, {"cell_type": "markdown", "id": "2454f011", "metadata": {"tags": ["learner", "md", "lect_05"]}, "source": ["Okay, let's look at a fixed signal frequency of 50%. The model with the highest value of $1/\\epsilon_{b}$ will be the best.\n", "\n", "This way of plotting shows that the multi-layer models can achieve huge improvements in background rejection if a reduction in signal efficiency is acceptable. However, it appears that we may have saturated the potential improvement already with the 2-layer version."]}, {"cell_type": "markdown", "id": "c6ae13f1", "metadata": {"tags": ["learner", "md", "lect_05"]}, "source": ["<h3>Batch Normalization and Dropout</h3>\n", "\n", "To finish, let's try two other types of regularizer: *batch normalization* and *dropout*.\n", "\n", "Batch normalization works by rescaling each input such that the mean and standard deviation are 0 and 1, respectively. This helps make sure that each node has similar values when it is passed to the following layer.\n", "\n", "Dropout works by randomly removing a given fraction of the nodes in a layer during each training pass. This helps ensure that no one node becomes crucially important to the final result."]}, {"cell_type": "markdown", "id": "7352bac2", "metadata": {"tags": ["learner", "md", "lect_05"]}, "source": ["First, we define both networks."]}, {"cell_type": "code", "execution_count": null, "id": "668597db", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_05"]}, "outputs": [], "source": ["#>>>RUN: L14.5-runcell05\n", "\n", "class MLP3_BN_net(torch.nn.Module):\n", "    def __init__(self):\n", "        super().__init__()\n", "        self.bn0 = torch.nn.BatchNorm1d(ninputs)\n", "        self.fc1 = torch.nn.Linear(ninputs,50)\n", "        self.act1 = torch.nn.ReLU()\n", "        self.bn1 = torch.nn.BatchNorm1d(50)\n", "        self.fc2 = torch.nn.Linear(50,30)\n", "        self.act2 = torch.nn.ReLU()\n", "        self.bn2 = torch.nn.BatchNorm1d(30)\n", "        self.fc3 = torch.nn.Linear(30,10)\n", "        self.act3 = torch.nn.ReLU()\n", "        self.bn3 = torch.nn.BatchNorm1d(10)\n", "        self.fc4 = torch.nn.Linear(10,1)\n", "        self.output = torch.nn.Sigmoid()\n", "\n", "    def forward(self, x):\n", "        x = self.bn0(x)\n", "        x = self.fc1(x)\n", "        x = self.act1(x)\n", "        x = self.bn1(x)\n", "        x = self.fc2(x)\n", "        x = self.act2(x)\n", "        x = self.bn2(x)\n", "        x = self.fc3(x)\n", "        x = self.act3(x)\n", "        x = self.bn3(x)\n", "        x = self.fc4(x)\n", "        x = self.output(x)\n", "        return x\n", "    \n", "class MLP3_Drop_net(torch.nn.Module):\n", "    def __init__(self):\n", "        super().__init__()\n", "        self.fc1 = torch.nn.Linear(ninputs,50)\n", "        self.act1 = torch.nn.ReLU()\n", "        self.drop1 = torch.nn.Dropout(0.1)\n", "        self.fc2 = torch.nn.Linear(50,30)\n", "        self.act2 = torch.nn.ReLU()\n", "        self.drop2 = torch.nn.Dropout(0.1)\n", "        self.fc3 = torch.nn.Linear(30,10)\n", "        self.act3 = torch.nn.ReLU()\n", "        self.drop3 = torch.nn.Dropout(0.1)\n", "        self.fc4 = torch.nn.Linear(10,1)\n", "        self.output = torch.nn.Sigmoid()\n", "\n", "    def forward(self, x):\n", "        x = self.fc1(x)\n", "        x = self.act1(x)\n", "        x = self.drop1(x)\n", "        x = self.fc2(x)\n", "        x = self.act2(x)\n", "        x = self.drop2(x)\n", "        x = self.fc3(x)\n", "        x = self.act3(x)\n", "        x = self.drop3(x)\n", "        x = self.fc4(x)\n", "        x = self.output(x)\n", "        return x\n", "\n", "torch.random.manual_seed(42)  # fix a random seed for reproducibility\n", "model_mlp_3layer_bn = MLP3_BN_net()\n", "print(model_mlp_3layer_bn)\n", "\n", "torch.random.manual_seed(42)  # fix a random seed for reproducibility\n", "model_mlp_3layer_drop = MLP3_Drop_net()\n", "print(model_mlp_3layer_drop)"]}, {"cell_type": "markdown", "id": "3faa84dc", "metadata": {"tags": ["learner", "md", "lect_05"]}, "source": ["Now, we train the network with batch normalization."]}, {"cell_type": "code", "execution_count": null, "id": "9a280529", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_05"]}, "outputs": [], "source": ["#>>>RUN: L14.5-runcell06\n", "\n", "history_mlp_3layer_bn = train(model_mlp_3layer_bn,trainloader,valloader,name='mlp_3layer_bn_model')\n", "Y_test_predict_mlp_3layer_bn, Y_test = apply(model_mlp_3layer_bn, testloader)"]}, {"cell_type": "markdown", "id": "1b09e4ff", "metadata": {"tags": ["learner", "md", "lect_05"]}, "source": ["Next, we train the dropout network."]}, {"cell_type": "code", "execution_count": null, "id": "be525e1d", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_05"]}, "outputs": [], "source": ["#>>>RUN: L14.5-runcell07\n", "\n", "history_mlp_3layer_drop = train(model_mlp_3layer_drop,trainloader,valloader,name='mlp_3layer_drop_model')\n", "Y_test_predict_mlp_3layer_drop, Y_test = apply(model_mlp_3layer_drop, testloader)"]}, {"cell_type": "markdown", "id": "950e4211", "metadata": {"tags": ["learner", "md", "lect_05"]}, "source": ["<h3>Looking at the ROC</h3>\n", "\n", "Finally, we look at the ROC and compare the standard 3-layer model with those using batch normalization and dropout regularization."]}, {"cell_type": "code", "execution_count": null, "id": "9bfb384c", "metadata": {"tags": ["learner", "py", "learner_chopped", "lect_05"]}, "outputs": [], "source": ["#>>>RUN: L14.5-runcell08\n", "\n", "mlp_3layer_rocpts = compute_ROC(Y_test,Y_test_predict_mlp_3layer,101)\n", "mlp_3layer_bn_rocpts = compute_ROC(Y_test,Y_test_predict_mlp_3layer_bn,101)\n", "mlp_3layer_drop_rocpts = compute_ROC(Y_test,Y_test_predict_mlp_3layer_drop,101)\n", "\n", "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(12,4))\n", "\n", "ax1.plot(mlp_3layer_rocpts[0],mlp_3layer_rocpts[1],'--',color='orange',label=\"MLP (3 hidden layers)\")\n", "ax1.plot(mlp_3layer_bn_rocpts[0],mlp_3layer_bn_rocpts[1],'--',color='brown',label=\"MLP (3 hidden layers w/ BN)\")\n", "ax1.plot(mlp_3layer_drop_rocpts[0],mlp_3layer_drop_rocpts[1],'--',color='cyan',label=\"MLP (3 hidden layers w/ Dropout)\")\n", "ax1.set_title(\"ROC (Receiver Operating Characteristic) Curve\")\n", "ax1.set_xlabel(\"Bkg Eff\")\n", "ax1.set_ylabel(\"Sig Eff\")\n", "ax1.legend(loc=\"lower right\")\n", "\n", "ax2.plot(1./mlp_3layer_rocpts[0],mlp_3layer_rocpts[1],'--',color='orange',label=\"MLP (3 hidden layers)\")\n", "ax2.plot(1./mlp_3layer_bn_rocpts[0],mlp_3layer_bn_rocpts[1],'--',color='brown',label=\"MLP (3 hidden layers w/ BN)\")\n", "ax2.plot(1./mlp_3layer_drop_rocpts[0],mlp_3layer_drop_rocpts[1],'--',color='cyan',label=\"MLP (3 hidden layers w/ Dropout)\")\n", "ax2.set_title(\"ROC (Receiver Operating Characteristic) Curve\")\n", "ax2.set_xlabel(\"1/Bkg Eff\")\n", "ax2.set_xlim([-1, 2500])\n", "ax2.set_ylabel(\"Sig Eff\")\n", "ax2.legend(loc=\"upper right\")\n", "\n", "plt.show()"]}, {"cell_type": "markdown", "id": "a767f533", "metadata": {"tags": ["learner", "md", "lect_05"]}, "source": ["You now have all the tools you need to start developing, training, and testing your own neural networks!"]}, {"cell_type": "markdown", "id": "5f3df180", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_14_5'></a>   \n", "\n", "| [Top](#section_14_0) | [Restart Section](#section_14_5) |\n"]}, {"cell_type": "markdown", "id": "36a59ef1", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-14.5.1</span>\n", "\n", "Which of the following statements is true about regularization in machine learning?\n", "\n", "A) Regularization is a technique used to increase the complexity of a model to improve its performance on new data.\\\n", "B) Regularization is a technique used to prevent overfitting by employing a variety of methods, including adding a penalty term to the loss function.\\\n", "C) Regularization is a technique used to reduce the size of the training data to improve generalization performance.\\\n", "D) Regularization is a technique used to randomly drop out neurons in a neural network during training.\\\n", "E) Regularization is a technique that normalizes the mean and variance of the activations of each layer in a neural network.\n"]}, {"cell_type": "markdown", "id": "b32128e7", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-14.5.2</span>\n", "\n", "For a fixed signal efficiency of 97%, what is the fractional reduction in rejection rate going from a 3 hidden layer model to ones adding either batch normalization or dropout? Complete the code below to do this calculation, then report your answer as a list of numbers with precision 1e-2: `[reduction with batch norm, reduction with dropout]`\n", "\n", "**HINT:** Use the function that you defined previously."]}, {"cell_type": "code", "execution_count": null, "id": "b4afa3ea", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L14.5.2\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def frac_reduc_fpr(array1, array2, sig_eff=0.97):\n", "    #false-positive-rate (background efficiency)\n", "    #true-positive-rate (signal efficiency):\n", "    array1_fpr = array1[0]\n", "    array1_tpr = array1[1]\n", "    array2_fpr = array2[0]\n", "    array2_tpr = array2[1]\n", "    \n", "    #find array_1_fpr where array_1_tpr is closest to sig_eff\n", "    array1_fpr_val = #YOUR CODE HERE\n", "    \n", "    #find array_2_fpr where array_2_tpr is closest to sig_eff\n", "    array2_fpr_val = #YOUR CODE HERE\n", "    \n", "    #calculate the fractional reduction in false-positive-rate\n", "    frac_red = #YOUR CODE HERE\n", "    \n", "    return frac_red\n", "\n", "\n", "#find where the signal efficiency is 97%\n", "print(\"Fractional Reduction from 3Layer to Batch Norm :\",frac_reduc_fpr(mlp_3layer_rocpts, mlp_3layer_bn_rocpts, 0.97))\n", "print(\"Fractional Reduction from 3Layer to Dropout:\",frac_reduc_fpr(mlp_3layer_rocpts, mlp_3layer_drop_rocpts, 0.97))"]}, {"cell_type": "markdown", "id": "f9e6b695", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-14.5.3</span>\n", "\n", "Try including both batch normalization *and* dropout. Do you get even better performance? Complete the code below to define and run this new model, then select the best answer from the following:\n", "\n", "A) Yes, it's definitely better to combine both regularization methods.\\\n", "B) No, combining methods was worse than models using either one separately.\\\n", "C) The combined model was maybe better than one model, but not better than both.       "]}, {"cell_type": "code", "execution_count": null, "id": "4d8184e4", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L14.5.3\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "class MLP3_BN_Dropout_net(torch.nn.Module):\n", "    #YOUR CODE HERE\n", "\n", "    \n", "torch.random.manual_seed(42)  # fix a random seed for reproducibility\n", "model_mlp_3layer_bn_drop = MLP3_BN_Dropout_net()\n", "print(model_mlp_3layer_bn)\n", "\n", "history_mlp_3layer_bn_drop = train(model_mlp_3layer_bn_drop,trainloader,valloader,name='mlp_3layer_bn_drop_model',nepochs=100)\n", "Y_test_predict_mlp_3layer_bn_drop, Y_test = apply(model_mlp_3layer_bn_drop, testloader)\n", "mlp_3layer_bn_drop_rocpts = compute_ROC(Y_test,Y_test_predict_mlp_3layer_bn_drop,501)\n", "    \n", "#find where the signal efficiency is 97%\n", "print(\"Fractional Reduction from Batch Norm to Combined Model:\",frac_reduc_fpr(mlp_3layer_bn_rocpts, mlp_3layer_bn_drop_rocpts, 0.97))\n", "print(\"Fractional Reduction from Dropout to Combined Model:\",frac_reduc_fpr(mlp_3layer_drop_rocpts, mlp_3layer_bn_drop_rocpts, 0.97))"]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}